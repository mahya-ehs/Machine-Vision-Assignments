{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Machine Vision\n",
    "## Assignment 3 - Binary image analysis\n",
    "\n",
    "## Personal details\n",
    "\n",
    "* **Name(s):** `PUT YOUR NAME(S) HERE.`\n",
    "* **Student ID(s):** `PUT YOUR STUDENT ID(S) HERE.`\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this assignment, you will implement a segmentation method to separate puzzle pieces from the background in an image of a jigsaw puzzle. The segmentation will use Otsu's method to automatically determine a threshold based on the grayscale histogram, dividing the image into dark and light regions. Once segmented, you will apply post-processing techniques to refine the binary image and improve the final result.\n",
    "\n",
    "<img src=\"fig1.jpg\">\n",
    "\n",
    "Let us start by displaying the test image and the corresponding grayscale histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = cv2.imread('puzzle.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.title('Image (gray)')\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.title('Grayscale histogram')\n",
    "h = plt.hist(gray.ravel(),256, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Notice that the image is quite noisy. This will make the segmentation more challenging. Before we continue with the segmentation, we want to reduce the noise. We will use the bilateral filter as it has the property of preserving edges and details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filt = cv2.bilateralFilter(gray,9,30,30)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Image (filtered)')\n",
    "plt.imshow(filt, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.title('Histogram (filtered)')\n",
    "h2 = plt.hist(filt.ravel(),256, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Manual segmentation\n",
    "\n",
    "Now that we have filtered the image, we continue with the segmentation. A pixel should be classified as foreground if its intensity is less than a threshold value. We can see from the histogram that a good threshold value is somewhere between the peaks (in the valley). Let us pick a threshold $t=125$ and segment the image. We use the OpenCV function __[`threshold`](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#threshold)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = 125\n",
    "ret,thresh = cv2.threshold(filt,t,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(filt, cmap='gray')\n",
    "plt.title('Image (gray)')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title('Thresholded')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 1 - Otsu's method (2 points)\n",
    "\n",
    "In the previous task, we chose the threshold manually. Otsu's method automates this process by looking at the histogram $P(i)$. It choses the threshold $t$ that minimizes the within-group variance defined as\n",
    "\n",
    "$$\n",
    "\\sigma_w^2(t) = q_1(t) \\sigma_1^2(t) + q_2(t) \\sigma_2^2(t),\\qquad (1)\n",
    "$$\n",
    "\n",
    "where $q_1(t)$ and $q_2(t)$ are the sums of histogram values\n",
    "\n",
    "$$\n",
    "q_1(t) = \\sum_{i=0}^{t-1} P(i) \\qquad q_2(t) = \\sum_{i=t}^{I-1} P(i) \\qquad (2)\n",
    "$$\n",
    "\n",
    "and $\\sigma_1^2(t)$ and $\\sigma_2^2(t)$ are variances\n",
    "\n",
    "$$\n",
    "\\sigma_1^2(t) = \\sum_{i=0}^{t-1} [i - \\mu_1(t)]^2 \\frac{P(i)}{q_1(t)}  \\qquad \\sigma_2^2(t) = \\sum_{i=t}^{I-1} [i - \\mu_2(t)]^2 \\frac{P(i)}{q_2(t)}. \\qquad (3)\n",
    "$$\n",
    "\n",
    "The mean values of the two distributions are\n",
    "\n",
    "$$\n",
    "\\mu_1(t) = \\sum_{i=0}^{t-1} \\frac{i P(i)}{q_1(t)}  \\qquad \\mu_2(t) = \\sum_{i=t}^{I-1} \\frac{i P(i)}{q_2(t)}. \\qquad (4)\n",
    "$$\n",
    "\n",
    "To implement Otsu's method, compute $\\sigma_w^2(t)$ (Eq.1 ) for all possible threshold values $t$. After that, choose the threshold that gives the smallest within-group variance $\\sigma_w^2(t)$.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Complete the function `computeGroupVariance` to calculate the within-group variance $\\sigma_w^2(t)$ for a given threshold $t$.\n",
    "\n",
    "1. Calculate $q_1(t)$ and $q_2(t)$ from the histogram $P(i)$ using Eq. 2.\n",
    "2. Calculate $\\mu_1(t)$, $\\mu_2(t)$ (Eq. 4), and the variances $\\sigma_1^2(t)$, $\\sigma_2^2(t)$ (Eq. 3).\n",
    "3. Return the within-group variance $\\sigma_w^2(t)$ (Eq. 1).\n",
    "\n",
    "**Tips!** Verify that your implementation works for all $t$ in the range $[0, 255]$. Add a small constant (e.g., $1 \\times 10^{-9}$) to $q_1(t)$ and $q_2(t)$ to avoid division by zero. Test the function with $t = 125$. The expected results are $\\sigma_w^2(t) \\approx 176.7$, $\\mu_1 \\approx 63.3$, and $\\mu_2 \\approx 181.9$. Run the provided code to confirm your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccde6a3aec199647bc4188252e6d321b",
     "grade": false,
     "grade_id": "otsu",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "# P : Histogram probabilities (255x1 vector)\n",
    "# t : Threshold value (scalar between [0,255])\n",
    "#\n",
    "# OUTPUT\n",
    "# varw  : Within-group variance (scalar)\n",
    "#\n",
    "def computeGroupVariance(P, t):\n",
    "    \n",
    "    # The following line can be removed\n",
    "    varw = 0\n",
    "      \n",
    "    # ---------- YOUR CODE STARTS HERE -----------\n",
    "    \n",
    "    # Compute q1 and q2 for a given threshold (Eq. 2)\n",
    "\n",
    "\n",
    "    # Compute mean values (Eq. 4)\n",
    "\n",
    "    \n",
    "    # Compute variances (Eq. 3)\n",
    "\n",
    "\n",
    "    # Compute within-group variance (Eq. 1)\n",
    "    \n",
    "    \n",
    "    # ----------- YOUR CODE ENDS HERE ------------\n",
    "    \n",
    "    return varw\n",
    "\n",
    "\n",
    "bins = np.arange(0,256,1)\n",
    "P = np.histogram(filt.ravel(),bins,density=True)[0]\n",
    "\n",
    "t = 125 # Threshold\n",
    "varw = computeGroupVariance(P,t)\n",
    "print(\"Within-group variance = %f (threshold %d)\" %(varw,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b5b31d12f85222bbd514d4f8955d395",
     "grade": true,
     "grade_id": "correct-otsu",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE EMPTY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Segmentation\n",
    "\n",
    "Next we are going to use the function to compute within-group variances for all thresholds. Then, we will choose the threshold that gives the smallest within-group variance. The threshold found using Otsu's method should be close to the threshold we picked manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresholds = np.arange(256)\n",
    "varws = np.zeros(256, dtype=np.float32)\n",
    "\n",
    "for idx, t in enumerate(thresholds):\n",
    "    varw = computeGroupVariance(P,t)\n",
    "    varws[idx] = varw\n",
    "    \n",
    "t = np.argmin(varws)\n",
    "print(\"Threshold = %d (within-group variance %f)\" %(t,varws[t]))\n",
    "\n",
    "ret, otsu = cv2.threshold(filt,t,255,cv2.THRESH_BINARY_INV)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(filt, cmap='gray')\n",
    "plt.title('Image (gray)')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(otsu, cmap='gray')\n",
    "plt.title(\"Otsu's method\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Post-processing (optional)\n",
    "\n",
    "The remaining steps of this notebook are optional and focus on refining the segmentation result. At this stage, the segmentation should be fairly accurate, but closer inspection reveals small holes, noise, and unwanted objects in the segmented image. To address these issues, we will refine the segmentation using morphological operations. \n",
    "\n",
    "**Morphological operations**\n",
    "\n",
    "The following code performs morphological closing to fill small holes in the segmented regions. This operation involves dilation followed by erosion and is effective in closing gaps within objects. Then, we will apply morphological opening to remove small noise and isolated regions. This operation consists of erosion followed by dilation.\n",
    "\n",
    "While these steps improve the segmentation, some larger unwanted objects remain. These will be addressed in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "closing = cv2.morphologyEx(otsu, cv2.MORPH_CLOSE, sel1)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(closing, cmap='gray')\n",
    "plt.title('Morphological closing')\n",
    "plt.axis('off')\n",
    "\n",
    "sel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, sel2)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(opening, cmap='gray')\n",
    "plt.title('Morphological opening')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Connected component labeling**\n",
    "\n",
    "The following code gives an unique label to each connected component in the binary image. It also extracts the contours of the objects. Notice that we still have more objects than we have puzzle pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret, labels = cv2.connectedComponents(opening)\n",
    "cnt,_ = cv2.findContours(opening, 1, 1)\n",
    "#_,cnt,_ = cv2.findContours(opening, 1, 1) # For older OpenCV versions\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(labels)\n",
    "plt.title('Labeled image')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "for i in range(len(cnt)):\n",
    "    plt.plot(cnt[i][:,0,0],cnt[i][:,0,1])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Contours')\n",
    "plt.axis('equal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Removing small ojects**\n",
    "\n",
    "As a final step, we remove those unwanted round objects. Luckily, they are much smaller than the puzzle pieces. We will compute the area of each contour using __[`contourArea`](https://docs.opencv.org/4.2.0/d3/dc0/group\\_\\_imgproc\\_\\_shape.html#ga2c759ed9f497d4a618048a2f56dc97f1)__ and keep objects, which area is more than 500. In the end, there are 36 objects in total (each jigsaw piece represents an object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will be the final result (binary image)\n",
    "final = np.zeros_like(otsu)\n",
    "\n",
    "for i in range(len(cnt)):\n",
    "    area = cv2.contourArea(cnt[i])\n",
    "    if (area > 500):\n",
    "        cv2.drawContours(final, cnt, i, 255, thickness=-1)\n",
    "\n",
    "ret, labels_final = cv2.connectedComponents(final)\n",
    "cnt_final,_ = cv2.findContours(final, 1, 1)\n",
    "#_,cnt_final,_ = cv2.findContours(final, 1, 1) # For older OpenCV versions\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(labels_final)\n",
    "plt.title('Labeled image')\n",
    "plt.title(\"Labeled image (objects = %d)\" %len(cnt_final))\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(final, cmap='gray')\n",
    "plt.title('Final segmentation')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**More advanced methods**\n",
    "\n",
    "Our test image was relatively easy to segment. This was mainly because the background was much brighter compared to the puzzle pieces. If the background was different color, the segmentation might not work anymore. In such case, one could utilize some color-based segmentation method. If the puzzle pieces were touching each other, it would cause another challenge. We might be able to separate the pieces from the background but the individual pieces would be difficult to extract (connected component labeling) as the segmented regions might be overlapping. The __[`watershed`](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#watershed)__ algorithm is a classical method that is often used to segment overlapping objects. Furthermore, OpenCV also offers __[`grabCut`](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#grabcut)__ segmentation method, which is based on graph cuts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Aftermath\n",
    "\n",
    "Please provide short answers to the following questions:\n",
    "\n",
    "**1. How much time did you need to complete this exercise?**\n",
    "\n",
    "`REPLACE THIS TEXT WITH YOUR ANSWER.`\n",
    "\n",
    "**2. Did you experience any issues or find anything particularly confusing?**\n",
    "\n",
    "`REPLACE THIS TEXT WITH YOUR ANSWER.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# References\n",
    "`List any references here (optional).`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "1. Go to `Kernel -> Restart & Clear Output` to remove all outputs.\n",
    "2. Compress this notebook (`MV_A3.ipynb`) into `MV_A3.zip`.\n",
    "3. Submit the **zip** file on Moodle.\n",
    "\n",
    "**Deadline: 2.2.2025**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
